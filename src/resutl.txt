_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 30, 30, 32)        320
_________________________________________________________________
activation_1 (Activation)    (None, 30, 30, 32)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248
_________________________________________________________________
activation_2 (Activation)    (None, 28, 28, 32)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 14, 14, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496
_________________________________________________________________
activation_3 (Activation)    (None, 12, 12, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928
_________________________________________________________________
activation_4 (Activation)    (None, 10, 10, 64)        0
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0
_________________________________________________________________
dropout_2 (Dropout)          (None, 5, 5, 64)          0
_________________________________________________________________
flatten_1 (Flatten)          (None, 1600)              0
_________________________________________________________________
dense_1 (Dense)              (None, 256)               409856
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0
_________________________________________________________________
dense_2 (Dense)              (None, 75)                19275
_________________________________________________________________
activation_6 (Activation)    (None, 75)                0
=================================================================
Total params: 494,123.0
Trainable params: 494,123.0
Non-trainable params: 0.0
_________________________________________________________________
Train on 9275 samples, validate on 2319 samples
Epoch 1/20
2017-05-27 05:28:57.124468: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-27 05:28:57.124510: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-27 05:28:57.124519: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
9275/9275 [==============================] - 43s - loss: 3.9201 - acc: 0.0774 - val_loss: 2.5601 - val_acc: 0.4588
Epoch 2/20
9275/9275 [==============================] - 42s - loss: 2.5701 - acc: 0.3298 - val_loss: 1.3239 - val_acc: 0.6809
Epoch 3/20
9275/9275 [==============================] - 42s - loss: 1.8105 - acc: 0.4967 - val_loss: 0.8331 - val_acc: 0.7715
Epoch 4/20
9275/9275 [==============================] - 42s - loss: 1.3546 - acc: 0.6000 - val_loss: 0.6609 - val_acc: 0.8284
Epoch 5/20
9275/9275 [==============================] - 42s - loss: 1.0929 - acc: 0.6746 - val_loss: 0.5079 - val_acc: 0.8525
Epoch 6/20
9275/9275 [==============================] - 42s - loss: 0.8884 - acc: 0.7344 - val_loss: 0.3885 - val_acc: 0.8892
Epoch 7/20
9275/9275 [==============================] - 42s - loss: 0.7499 - acc: 0.7653 - val_loss: 0.3345 - val_acc: 0.8974
Epoch 8/20
9275/9275 [==============================] - 42s - loss: 0.6575 - acc: 0.7944 - val_loss: 0.2927 - val_acc: 0.9017
Epoch 9/20
9275/9275 [==============================] - 42s - loss: 0.5835 - acc: 0.8102 - val_loss: 0.2471 - val_acc: 0.9207
Epoch 10/20
9275/9275 [==============================] - 42s - loss: 0.5269 - acc: 0.8339 - val_loss: 0.2137 - val_acc: 0.9276
Epoch 11/20
9275/9275 [==============================] - 42s - loss: 0.4665 - acc: 0.8534 - val_loss: 0.1960 - val_acc: 0.9383
Epoch 12/20
9275/9275 [==============================] - 42s - loss: 0.4078 - acc: 0.8685 - val_loss: 0.2010 - val_acc: 0.9267
Epoch 13/20
9275/9275 [==============================] - 42s - loss: 0.3945 - acc: 0.8798 - val_loss: 0.1850 - val_acc: 0.9375
Epoch 14/20
9275/9275 [==============================] - 42s - loss: 0.3645 - acc: 0.8839 - val_loss: 0.1768 - val_acc: 0.9426
Epoch 15/20
9275/9275 [==============================] - 42s - loss: 0.3284 - acc: 0.8954 - val_loss: 0.1683 - val_acc: 0.9366
Epoch 16/20
9275/9275 [==============================] - 42s - loss: 0.3115 - acc: 0.8950 - val_loss: 0.1558 - val_acc: 0.9422
Epoch 17/20
9275/9275 [==============================] - 42s - loss: 0.2996 - acc: 0.9030 - val_loss: 0.1519 - val_acc: 0.9474
Epoch 18/20
9275/9275 [==============================] - 42s - loss: 0.2783 - acc: 0.9108 - val_loss: 0.1402 - val_acc: 0.9457
Epoch 19/20
9275/9275 [==============================] - 42s - loss: 0.2565 - acc: 0.9142 - val_loss: 0.1318 - val_acc: 0.9513
Epoch 20/20
9275/9275 [==============================] - 42s - loss: 0.2427 - acc: 0.9247 - val_loss: 0.1314 - val_acc: 0.9517

Test score   : 0.1314
Test accuracy: 0.9517
